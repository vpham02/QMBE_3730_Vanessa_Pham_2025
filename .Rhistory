q()
q()
# Example 7.12
data("crime1")
# Generate arr86
arr86 <- as.numeric(crime1$narr86 > 0)
install.packages("tidyverse")
install.packages("stargazer")
library(tidyverse)
library(stargazer)
install.packages("wooldridge")
library(wooldridge)
# Example 7.12
data("crime1")
# Generate arr86
arr86 <- as.numeric(crime1$narr86 > 0)
lm.7.12 <- lm(arr86 ~ pcnv + avgsen + tottime + ptime86 + qemp86, data = crime1)
summary(lm.7.12)
# Equation 7.32
lm.e7.32 <- lm(arr86 ~ pcnv + avgsen + tottime + ptime86 + qemp86 +
black + hispan, data = crime1)
summary(lm.e7.32)
# Equation 7.33
lm.e7.33 <- lm(lscrap ~ grant + lsales + lemploy, data = jtrain[jtrain$d88 == 1,])
summary(lm.e7.33)
View(fertil3)
reg.1 <- lm(gfr ~ t, data = fertil3)
summary(reg.1)
reg.1a <- lm(gfr ~ year, data = fertil3)
summary(reg.1a)
help(gfr)
reg.2 <- lm(gfr ~ t + tsq, data = fertil3)
summary(reg.2)
ln.gfr <- log(fertil3$gfr)
reg.3 <- lm(ln.gfr ~ t, data = fertil3)
summary(reg.3)
reg.4 <- lm(gfr ~ pe + ww2 + pill, data = fertil3)
summary(reg.4)
reg.5 <- lm(gfr~ pe + pe_1 + ww2 + pill, data = fertil3)
summary(reg.5)
reg.5 <- lm(gfr~ pe + pe_1 + pe_2 + ww2 + pill, data = fertil3)
summary(reg.5)
-0.073 - 0.0058 + 0.04
0.073 - 0.0058 + 0.04
#f - stat
((0.4986 - 0.4734)/2) / (1-0.4986)/64)
#f - stat
((0.4986 - 0.4734)/2) / ((1-0.4986)/64)
reg.6 <- lm(gfr~ pe + pe_1 + pe_2 + pe_3 + pe_4 + ww2 + pill, data = fertil3)
summary(reg.6)
#LRP
0.088749 - 0.0039 + 0.007 + 0.018 + 0.014
## Are the lagged terms significant as a block?
#f-stat
((0.5368 - 0.4734)/4)/((1-0.5368)/60)
data <- read.csv('admit')
getwd()
setwd("C:/Users/vanes/OneDrive/Desktop/QMBE_3730_Vanessa_Pham_2025/QMBE_3730_Vanessa_Pham_2025")
install.packages("tidyverse")
install.packages("stargazer")
library(tidyverse)
library(stargazer)
install.packages("wooldridge")
library(wooldridge)
data <- read.csv('admit')
data <- read.csv('admit')
setwd("C:/Users/vanes/OneDrive/Desktop/QMBE_3730_Vanessa_Pham_2025/QMBE_3730_Vanessa_Pham_2025")
data <- read.csv('admit.csv')
view(data)
admit <- data$admit
admit_eda <- glm(admit ~ gre + gpa + rank, data = data, family = "binomial")
summary(admit_eda)
help("data")
help(admit)
exp(coef(admit_eda))
exp(coef(admit_eda))
predict(admit_eda, type = "response")
glance(admit_eda)
# Load dataset
data("mtcars")
View(mtcars) #View data set.
# Convert 'am' to a factor (categorical variable)
mtcars$am <- as.factor(mtcars$am)
view(mtcars$am)
admit <- as.factor(admit$admit)
admit <- as.factor(data$admit)
view(admit)
summary(data)
str(data)
str(data)
admit_eda <- glm(admit ~ gre + gpa + rank, data = data, family = "binomial")
str(data)
set.seed(1)
split <- sample.split(data, SplitRatio = 0.7)
split <- sample.split(data, SplitRatio = 0.7)
library(caTools)
library(modelr)
library(broom)
sample <- sample(c(TRUE, FALSE), nrow(default), replace = T, prob = c(0.6, 0.4))
sample <- sample(c(TRUE, FALSE), nrow(admit), replace = T, prob = c(0.6, 0.4))
sample <- sample(c(TRUE, FALSE), nrow(admit), replace = T, prob = c(0.7, 0.3))
split <- sample.split(data, SplitRatio = 0.7)
# Split the data into training and testing sets.
# Set seed for reproducibility
set.seed(1)
# Split the dataset into training (70%) and testing (30%)
split <- sample.split(mtcars$am, SplitRatio = 0.7)
library(caTools)
# Load libraries
library(tidyverse)
library(caTools)
install.packages("caTools")
library(caTools)
split <- sample.split(data, SplitRatio = 0.7)
train_data <- subset(data, split == TRUE)
test_data <- subset(data, split == FALSE)
dim(train_data)
dim(test_data)
admit_eda <- glm(admit ~ gre + gpa + rank, data = data, family = "binomial")
summary(admit_eda)
exp(coef(admit_eda))
hist(data$gre)
# Predict probabilities on the test dataset
pred_probs <- predict(log_model, test_data, type = "response")
# Train the logistic regression model
log_model <- glm(am ~ mpg + hp + wt, data = train_data, family = binomial) # Binomial Distribution, Y variable is binary
# Load dataset
data("mtcars")
# Convert 'am' to a factor (categorical variable)
mtcars$am <- as.factor(mtcars$am)
view(mtcars$am)
# Split the data into training and testing sets.
# Set seed for reproducibility
set.seed(1)
# Split the dataset into training (70%) and testing (30%)
split <- sample.split(mtcars$am, SplitRatio = 0.7)
# Create training and testing sets
# https://search.r-project.org/CRAN/refmans/caTools/html/sample.split.html
train_data <- subset(mtcars, split == TRUE)
test_data <- subset(mtcars, split == FALSE)
# Check dataset dimensions
dim(train_data)
dim(test_data)
# Train the logistic regression model
log_model <- glm(am ~ mpg + hp + wt, data = train_data, family = binomial) # Binomial Distribution, Y variable is binary
# Display model summary
summary(log_model)
# Predict probabilities on the test dataset
pred_probs <- predict(log_model, test_data, type = "response")
pred_probs
# Convert probabilities to binary predictions (threshold = 0.5)
pred_classes <- ifelse(pred_probs > 0.5, 1, 0)
# Convert to factor for comparison
pred_classes <- as.factor(pred_classes)
# Display predictions
head(pred_probs)
head(pred_classes)
pred_admit <- predict(admit_eda, type = "response")
pred_classes <- ifelse(pred_admit > 0.5, 1, 0)
pred_classes
pred_classes_1 <- ifelse(pred_admit > 0.5, 1, 0)
pred_classes
pred_classes_1
pred_classes_1 <- as.factor(pred_classes_1)
head(pred_admit)
head(pred_classes_1)
glance(admit_eda)
### Print predictions and true y values as dataframe
do.call(rbind, Map(data.frame, predicted_classes=pred_classes, am=test_data$am))
plot(data$gre)
hist(data$gre, freq = FALSE)
lines(density(data$gre))
head(pred_classes_1)
head(pred_admit)
head(pred_classes_1)
### Print predictions and true y values as dataframe
do.call(rbind, Map(data.frame, predicted_classes=pred_classes, am=test_data$am))
test_data <- subset(data, split == FALSE)
set.seed(1)
split <- sample.split(data, SplitRatio = 0.7)
train_data <- subset(data, split == TRUE)
test_data <- subset(data, split == FALSE)
dim(train_data)
dim(test_data)
do.call(rbind, Map(data.frame, pred_admit=pred_classes_1, admit=test_data$admit))
summary(admit_eda)
conf_matrix <- table(Predicted = pred_classes_1, Actual = test_data$admit)
conf_matrix <- table(Predicted = pred_admit, Actual = test_data$admit)
#From what I understand, "0" is not admited and "1" is admited to graduate school.
#After running the EDA regression holding all else equal, as Graduate Record Exam
#scores increase by 1 unit, there is a increase 1.00230 odds of the individual being admited to graduate school
#As GPA increase by 1 unit, there is a increase 2.17497 odds of the individual being admited to grauate school which doubles the odds
#As the rank of the undergraduate increases by 1 rank, there is a 0.57119 odds of the individual being admited to graduate school
#As for the intercept, if all of the independant variables are 0, there is a 0.03176 odds of the individual being admited to gradute school
#It is not balanced because 70% of people were not admitted and 30% of people were admitted
pred_classes_1
test_data$admit
pred_classes
pred_admit <- predict(admit_eda, type = "response")
pred_admit_class <- ifelse(pred_admit > 0.5, 1, 0)
pred_admit_class <- as.factor(pred_classes_1)
head(pred_admit_class)
do.call(rbind, Map(data.frame, pred_admit=pred_admit_class, admit=test_data$admit))
hist(data$gre, freq = FALSE)
lines(density(data$gre))
conf_matrix <- table(Predicted = pred_admit, Actual = test_data$admit)
admit_eda <- glm(admit ~ gre + gpa + rank, data = data, family = "binomial")
summary(admit_eda)
exp(coef(admit_eda))
pred_admit <- predict(admit_eda, type = "response")
pred_admit_class <- ifelse(pred_admit > 0.5, 1, 0)
pred_admit_class <- as.factor(pred_classes_1)
head(pred_admit)
head(pred_admit_class)
do.call(rbind, Map(data.frame, pred_admit=pred_admit_class, admit=test_data$admit))
# Display predictions
head(pred_probs)
head(pred_classes)
### Print predictions and true y values as dataframe
do.call(rbind, Map(data.frame, predicted_classes=pred_classes, am=test_data$am))
# Convert to factor for comparison
pred_classes <- as.factor(pred_classes)
# Display predictions
head(pred_probs)
head(pred_classes)
do.call(rbind, Map(data.frame, pred_admit=pred_admit_class, admit=test_data$admit))
### Print predictions and true y values as dataframe
do.call(rbind, Map(data.frame, predicted_classes=pred_classes, am=test_data$am))
summary(mtcars$am)
view(mtcars)
conf_matrix <- table(Predicted = pred_admit, Actual = test_data$admit)
conf_matrix <- table(Predicted = pred_admit_class, Actual = test_data$admit)
admit_eda <- glm(admit ~ gre + gpa + rank, data = train_data, family = "binomial")
exp(coef(admit_eda))
exp(coef(admit_eda))
pred_admit <- predict(admit_eda, type = "response")
pred_admit_class <- ifelse(pred_admit > 0.5, 1, 0)
pred_admit_class <- as.factor(pred_classes_1)
head(pred_admit)
head(pred_admit_class)
do.call(rbind, Map(data.frame, pred_admit=pred_admit_class, admit=test_data$admit))
hist(data$gre, freq = FALSE)
lines(density(data$gre))
conf_matrix <- table(Predicted = pred_admit_class, Actual = test_data$admit)
split <- sample.split(data, SplitRatio = 0.7)
train_data <- subset(data, split == TRUE)
test_data <- subset(data, split == FALSE)
dim(train_data)
dim(test_data)
admit_eda <- glm(admit ~ gre + gpa + rank, data = train_data, family = "binomial")
summary(admit_eda)
exp(coef(admit_eda))
pred_admit <- predict(admit_eda, type = "response")
pred_admit_class <- ifelse(pred_admit > 0.5, 1, 0)
pred_admit_class <- as.factor(pred_classes_1)
head(pred_admit)
head(pred_admit_class)
do.call(rbind, Map(data.frame, pred_admit=pred_admit_class, admit=test_data$admit))
hist(data$gre, freq = FALSE)
lines(density(data$gre))
glance(admit_eda)
conf_matrix <- table(Predicted = pred_admit_class, Actual = test_data$admit)
do.call(rbind, Map(data.frame, pred_admit=pred_admit_class, admit=test_data$admit))
split <- sample.split(data, SplitRatio = 0.7)
train_data_1 <- subset(data, split == TRUE)
test_data_1 <- subset(data, split == FALSE)
dim(train_data_1)
dim(test_data_1)
data
admit_eda <- glm(admit ~ gre + gpa + rank, data = train_data_1, family = "binomial")
summary(admit_eda)
exp(coef(admit_eda))
pred_admit <- predict(admit_eda, type = "response")
pred_admit_class <- ifelse(pred_admit > 0.5, 1, 0)
pred_admit_class <- as.factor(pred_classes_1)
head(pred_admit)
head(pred_admit_class)
do.call(rbind, Map(data.frame, pred_admit=pred_admit_class, admit=test_data$admit))
do.call(rbind, Map(data.frame, pred_admit=pred_admit_class, admit=test_data_1$admit))
conf_matrix <- table(Predicted = pred_admit_class, Actual = test_data$admit)
conf_matrix_1 <- table(Predicted = pred_admit_class, Actual = test_data$admit)
conf_matrix_1 <- table(Predicted = pred_admit_class, Actual = test_data_1$admit)
test_data_1$admit
summary(admit_eda)
exp(coef(admit_eda))
admit_eda <- glm(admit ~ gre + gpa + rank, data = data, family = "binomial")
summary(admit_eda)
exp(coef(admit_eda))
pred_admit_class <- as.factor(pred_admit_class)
head(pred_admit)
head(pred_admit_class)
do.call(rbind, Map(data.frame, pred_admit=pred_admit_class, admit=test_data_1$admit))
conf_matrix_1 <- table(Predicted = pred_admit_class, Actual = test_data_1$admit)
conf_matrix_1 <- table(Predicted = pred_admit_class, Actual = data$admit)
conf_matrix_1
admit_accuracy <- sum(diag(conf_matrix_1)) / sum(conf_matrix_1)
admit_accuracy
print(conf_matrix_1)
print(paste("Accuracy:", round(accuracy = 4)))
print(paste("Accuracy:", round(accuracy, 4)))
# Print results
print(conf_matrix)
# Create confusion matrix
conf_matrix <- table(Predicted = pred_classes, Actual = test_data$am)
admit_eda <- glm(admit ~ gre + gpa + rank, data = data, family = "binomial")
summary(admit_eda)
